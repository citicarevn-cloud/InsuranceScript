import streamlit as st
import google.generativeai as genai
# gTTS ƒë√£ b·ªã lo·∫°i b·ªè ho√†n to√†n ƒë·ªÉ kh√¥ng bao gi·ªù ra gi·ªçng Google
import tempfile
import os
import requests
import re
import time
import random
import asyncio
import edge_tts
import concurrent.futures
from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips, ColorClip

# --- 1. C·∫§U H√åNH APP (ƒê√É ƒê·ªîI T√äN) ---
st.set_page_config(page_title="Insurance Script", layout="wide", page_icon="üõ°Ô∏è")

# --- CSS GIAO DI·ªÜN ---
st.markdown("""
    <style>
    .stButton>button {background-color: #0068C9; color: white; font-weight: bold; border-radius: 8px; height: 3em; width: 100%;}
    img {border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); margin: 10px 0;}
    .stProgress > div > div > div > div { background-color: #28a745; }
    /* ·∫®n b·ªõt c√°c element th·ª´a */
    header {visibility: hidden;}
    </style>
""", unsafe_allow_html=True)

# --- QU·∫¢N L√ù TR·∫†NG TH√ÅI ---
if 'feedback_history' not in st.session_state: st.session_state.feedback_history = []
if 'video_settings' not in st.session_state: st.session_state.video_settings = {'w': 1280, 'h': 720}

# --- C·∫§U H√åNH VOICE ID ---
VOICE_MAP = {
    "Chuy√™n nghi·ªáp": "mJLZ5p8I7Pk81BHpKwbx",  # Nam Sadoma
    "ƒê·ªùi th∆∞·ªùng": "foH7s9fX31wFFH2yqrFa",     # Huyen
    "C·∫£m ƒë·ªông": "1l0C0QA9c9jN22EmWiB0",       # Jade
    "H√†i h∆∞·ªõc": "JxmKvRaNYFidf0N27Vng"        # Son Tran
}

# --- SIDEBAR (B·∫¢NG ƒêI·ªÄU KHI·ªÇN) ---
with st.sidebar:
    st.header("üéõÔ∏è C·∫•u h√¨nh h·ªá th·ªëng")
    
    if st.button("üîÑ L√ÄM M·ªöI (RESET)"):
        st.session_state.clear()
        st.rerun()

    # 1. NH·∫¨P KEY (T·ª∞ ƒê·ªòNG L·∫§Y T·ª™ SECRETS)
    api_key = st.secrets.get("GEMINI_API_KEY", "").strip()
    eleven_api = st.secrets.get("ELEVEN_API_KEY", "").strip()
    hf_token = st.secrets.get("HUGGINGFACE_TOKEN", "").strip()

    # Ki·ªÉm tra tr·∫°ng th√°i Key
    if api_key: st.success("‚úÖ Gemini: S·∫µn s√†ng")
    else: st.error("‚ùå Thi·∫øu Gemini Key")
        
    if eleven_api: st.success("‚úÖ ElevenLabs: S·∫µn s√†ng")
    else: st.warning("‚ö†Ô∏è Thi·∫øu ElevenLabs Key (S·∫Ω d√πng Microsoft)")
        
    if hf_token: st.success("‚úÖ HuggingFace: S·∫µn s√†ng")
    else: st.error("‚ùå Thi·∫øu HuggingFace Token (Kh√¥ng th·ªÉ t·∫°o ·∫£nh)")

    st.divider()
    
    # 2. CH·ªåN MODEL GEMINI
    st.subheader("üß† B·ªô n√£o x·ª≠ l√Ω")
    available_models = ["models/gemini-1.5-flash"] # M·∫∑c ƒë·ªãnh nhanh
    if api_key:
        try:
            genai.configure(api_key=api_key)
            models = genai.list_models()
            available_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        except: pass
    selected_model = st.selectbox("Ch·ªçn Model:", available_models, index=0)

    st.divider()

    # 3. CH·ªåN GI·ªåNG ƒê·ªåC (KH√îNG C√ì GOOGLE)
    st.subheader("üîä Ngu·ªìn gi·ªçng ƒë·ªçc")
    tts_provider = st.selectbox("Ch·ªçn Server:", ["ElevenLabs (VIP)", "Microsoft (Mi·ªÖn ph√≠)"])
    
    edge_voice = "vi-VN-HoaiMyNeural" 
    if "Microsoft" in tts_provider:
        edge_voice = st.selectbox("Gi·ªçng Microsoft:", [
            "vi-VN-HoaiMyNeural (N·ªØ)", "vi-VN-NamMinhNeural (Nam)"
        ]).split(" ")[0]

# --- H√ÄM X·ª¨ L√ù TEXT ---
def clean_text_for_audio(text):
    # Lo·∫°i b·ªè ch·ªâ d·∫´n c·∫£nh, l·ªùi b√¨nh, k√Ω t·ª± ƒë·∫∑c bi·ªát
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\(.*?\)', '', text)
    prefixes = ["L·ªùi b√¨nh:", "Audio:", "Voice:", "Thuy·∫øt minh:", "Host:", "MC:", "Scene \d+:"]
    for p in prefixes:
        text = re.sub(f'{p}', '', text, flags=re.IGNORECASE)
    text = text.replace("*", "").replace("#", "").replace("- ", "").replace('"', '')
    return text.strip()

# --- H√ÄM T·∫†O AUDIO (STRICT MODE - KH√îNG GOOGLE) ---
async def generate_edge_tts(text, voice, filename):
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(filename)

def generate_audio_strict(text, filename, tone_key="Chuy√™n nghi·ªáp"):
    clean_text = clean_text_for_audio(text)
    if not clean_text: return False
    
    # 1. ELEVENLABS
    if "ElevenLabs" in tts_provider:
        if not eleven_api:
            st.error("‚ùå B·∫°n ch·ªçn ElevenLabs nh∆∞ng ch∆∞a c√≥ Key!")
            return False
            
        voice_id = VOICE_MAP.get(tone_key, "mJLZ5p8I7Pk81BHpKwbx")
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
        headers = {"xi-api-key": eleven_api, "Content-Type": "application/json"}
        # D√πng model Turbo cho nhanh
        data = {"text": clean_text, "model_id": "eleven_turbo_v2"} 
        
        try:
            response = requests.post(url, json=data, headers=headers, timeout=60)
            if response.status_code == 200:
                with open(filename, 'wb') as f: f.write(response.content)
                return True
            else:
                # B√°o l·ªói r√µ r√†ng
                st.error(f"‚ùå ElevenLabs L·ªói {response.status_code}: {response.text}")
                return False 
        except Exception as e:
            st.error(f"‚ùå L·ªói m·∫°ng ElevenLabs: {e}")
            return False

    # 2. MICROSOFT
    if "Microsoft" in tts_provider:
        try:
            asyncio.run(generate_edge_tts(clean_text, edge_voice, filename))
            return True
        except Exception as e:
            st.error(f"‚ùå L·ªói Microsoft TTS: {e}")
            return False

    return False

# --- H√ÄM T·∫†O ·∫¢NH (HUGGING FACE ONLY - KH√îNG POLLINATIONS) ---
def generate_image_hf_only(prompt, width, height):
    if not hf_token: return None

    # Model SDXL chu·∫©n
    API_URL = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"
    headers = {"Authorization": f"Bearer {hf_token}"}
    
    style = ", high quality illustration, isometric style, flat design, cinematic lighting, no text"
    full_prompt = prompt + style
    if width < height: full_prompt += ", vertical, 9:16 portrait"
    else: full_prompt += ", wide angle, 16:9 landscape"

    # Th·ª≠ 3 l·∫ßn
    for i in range(3):
        try:
            response = requests.post(API_URL, headers=headers, json={"inputs": full_prompt}, timeout=25)
            if response.status_code == 200:
                return response.content
            elif response.status_code == 503: # Model ƒëang load
                time.sleep(2)
            else:
                time.sleep(1)
        except: time.sleep(1)
    return None

# --- H√ÄM D·ª∞NG SCENE ---
def process_scene_strict(args):
    part, width, height, tone = args
    try:
        if "|" in part:
            data = part.split("|")
            if len(data) < 2: return None
            
            img_prompt = data[0].replace("Scene", "").replace(":", "").strip()
            raw_voice_text = data[1].strip()
            
            # 1. Audio
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                audio_path = f.name
            
            if not generate_audio_strict(raw_voice_text, audio_path, tone):
                return None # Kh√¥ng c√≥ ti·∫øng th√¨ b·ªè qua lu√¥n

            # 2. ·∫¢nh (Ch·ªâ HF)
            img_content = generate_image_hf_only(img_prompt, width, height)
            
            if img_content:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as f:
                    f.write(img_content); img_path = f.name
                return (audio_path, img_path)
            else:
                return (audio_path, "PLACEHOLDER")
    except: return None

def create_video_strict(script_data, width, height, tone):
    lines = [line for line in script_data.strip().split('\n') if "|" in line and "Scene" in line]
    if len(lines) > 10: lines = lines[:10] # Max 10 c·∫£nh
    
    total = len(lines)
    if total == 0: return None

    bar = st.progress(0)
    st.caption("üöÄ ƒêang x·ª≠ l√Ω t√†i nguy√™n (Tu·∫ßn t·ª± ƒë·ªÉ an to√†n)...")
    
    args = [(line, width, height, tone) for line in lines]
    results = []
    
    # Ch·∫°y tu·∫ßn t·ª± 1 lu·ªìng
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        for i, res in enumerate(executor.map(process_scene_strict, args)):
            results.append(res)
            bar.progress(int((i+1)/total * 100))
            
    st.caption("üé¨ ƒêang gh√©p video...")
    clips = []
    for asset in results:
        if asset:
            apath, ipath = asset
            try:
                ac = AudioFileClip(apath)
                if ipath == "PLACEHOLDER":
                    # M√†n h√¨nh ƒëen n·∫øu ·∫£nh l·ªói
                    clip = ColorClip(size=(width, height), color=(0,0,0), duration=ac.duration+0.5)
                else:
                    clip = ImageClip(ipath).set_duration(ac.duration+0.5)
                
                clip = clip.set_audio(ac).set_fps(15)
                clips.append(clip)
            except: pass

    if clips:
        final = concatenate_videoclips(clips, method="compose")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as f:
            final.write_videofile(f.name, codec='libx264', audio_codec='aac', fps=15, preset='ultrafast', threads=4)
        bar.empty()
        return f.name
    return None

def render_mixed_content(text, width=800, height=450):
    parts = re.split(r'\{{1,2}IMAGE:?\s*(.*?)\}{1,2}', text, flags=re.IGNORECASE)
    for i, part in enumerate(parts):
        if i % 2 == 0:
            if part.strip(): st.markdown(part)
        else:
            prompt = part.strip().replace("}", "").replace("{", "")
            if prompt:
                data = generate_image_hf_only(prompt, width, height)
                if data: st.image(data, caption=f"üé® {prompt}", use_container_width=True)

# --- GIAO DI·ªÜN CH√çNH ---
st.title("üõ°Ô∏è Insurance Script") # ƒê√£ ƒë·ªïi t√™n
