import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import tempfile
import os
import requests
import re
import time
import random
import asyncio
import edge_tts
import concurrent.futures
from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="DAT Media AI Studio", layout="wide", page_icon="ğŸ™ï¸")

# --- CSS TÃ™Y CHá»ˆNH ---
st.markdown("""
    <style>
    .stButton>button {background-color: #0068C9; color: white; font-weight: bold; border-radius: 8px; height: 3em; width: 100%;}
    img {border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); margin: 10px 0;}
    .stProgress > div > div > div > div { background-color: #28a745; }
    </style>
""", unsafe_allow_html=True)

# --- QUáº¢N LÃ SESSION ---
if 'feedback_history' not in st.session_state: st.session_state.feedback_history = []
if 'video_settings' not in st.session_state: st.session_state.video_settings = {'w': 1280, 'h': 720}

# --- Cáº¤U HÃŒNH VOICE ID (Cá» Äá»ŠNH - GIá»® NGUYÃŠN) ---
VOICE_MAP = {
    "ChuyÃªn nghiá»‡p": "mJLZ5p8I7Pk81BHpKwbx",  # Nam Sadoma
    "Äá»i thÆ°á»ng": "foH7s9fX31wFFH2yqrFa",     # Huyen
    "Cáº£m Ä‘á»™ng": "1l0C0QA9c9jN22EmWiB0",       # Jade
    "HÃ i hÆ°á»›c": "JxmKvRaNYFidf0N27Vng"        # Son Tran
}

# --- SIDEBAR ---
with st.sidebar:
    st.header("ğŸ›ï¸ Cáº¥u hÃ¬nh há»‡ thá»‘ng")
    
    if st.button("ğŸ”„ LÃ€M Má»šI (RESET)"):
        saved = st.session_state.feedback_history
        st.session_state.clear()
        st.session_state.feedback_history = saved
        st.rerun()

    # 1. API KEY (GIá»® NGUYÃŠN)
    api_key = st.secrets.get("GEMINI_API_KEY", "")
    eleven_api = st.secrets.get("ELEVEN_API_KEY", "")

    if api_key:
        st.success(f"âœ… Gemini API: ÄÃ£ káº¿t ná»‘i")
    else:
        api_key = st.text_input("Gemini API Key", type="password")
        
    if eleven_api:
        st.success(f"âœ… ElevenLabs API: ÄÃ£ káº¿t ná»‘i")
    else:
        eleven_api = st.text_input("ElevenLabs API Key", type="password")

    st.divider()
    
    # 2. CHá»ŒN MODEL (ÄÃƒ KHÃ”I PHá»¤C TÃNH NÄ‚NG QUÃ‰T)
    st.subheader("ğŸ§  Bá»™ nÃ£o xá»­ lÃ½")
    
    # Logic quÃ©t model tá»± Ä‘á»™ng
    available_models = ["models/gemini-pro"] # Máº·c Ä‘á»‹nh an toÃ n
    if api_key:
        try:
            genai.configure(api_key=api_key)
            # Láº¥y danh sÃ¡ch thá»±c táº¿ tá»« Project cá»§a báº¡n
            models = genai.list_models()
            available_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]
        except Exception as e:
            st.error(f"KhÃ´ng quÃ©t Ä‘Æ°á»£c model: {e}")
            
    # Cho phÃ©p ngÆ°á»i dÃ¹ng chá»n tá»« danh sÃ¡ch Ä‘Ã£ quÃ©t
    selected_model = st.selectbox("Chá»n Model:", available_models, index=0)

    st.divider()

    # 3. Cáº¤U HÃŒNH GIá»ŒNG Äá»ŒC (GIá»® NGUYÃŠN)
    st.subheader("ğŸ”Š Nguá»“n giá»ng Ä‘á»c")
    tts_provider = st.selectbox("Chá»n Server:", ["ElevenLabs (VIP - NÃªn dÃ¹ng)", "Microsoft (Miá»…n phÃ­)", "Google (CÆ¡ báº£n)"])
    
    edge_voice = "vi-VN-HoaiMyNeural" 
    if "Microsoft" in tts_provider:
        edge_voice = st.selectbox("Chá»n giá»ng MS:", [
            "vi-VN-HoaiMyNeural (Ná»¯ - Truyá»n cáº£m)", 
            "vi-VN-NamMinhNeural (Nam - Tráº§m áº¥m)"
        ]).split(" ")[0]

# --- HÃ€M Xá»¬ LÃ (GIá»® NGUYÃŠN CÃC CHá»¨C NÄ‚NG Tá»T) ---

def clean_text_for_audio(text):
    """LÃ m sáº¡ch vÄƒn báº£n"""
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\(.*?\)', '', text)
    prefixes = ["Lá»i bÃ¬nh:", "Audio:", "Voice:", "Thuyáº¿t minh:", "Host:", "MC:", "Scene \d+:"]
    for p in prefixes:
        text = re.sub(f'{p}', '', text, flags=re.IGNORECASE)
    text = text.replace("*", "").replace("#", "").replace("- ", "").replace('"', '')
    return text.strip()

async def generate_edge_tts(text, voice, filename):
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(filename)

def generate_audio_unified(text, filename, tone_key="ChuyÃªn nghiá»‡p"):
    clean_text = clean_text_for_audio(text)
    if not clean_text: return False
    
    # ElevenLabs
    if "ElevenLabs" in tts_provider and eleven_api:
        voice_id = VOICE_MAP.get(tone_key, "mJLZ5p8I7Pk81BHpKwbx") 
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
        headers = {"xi-api-key": eleven_api, "Content-Type": "application/json"}
        data = {"text": clean_text, "model_id": "eleven_multilingual_v2"}
        try:
            response = requests.post(url, json=data, headers=headers)
            if response.status_code == 200:
                with open(filename, 'wb') as f: f.write(response.content)
                return True
        except: pass 
        
    # Microsoft Edge TTS
    if "Microsoft" in tts_provider:
        try:
            asyncio.run(generate_edge_tts(clean_text, edge_voice, filename))
            return True
        except: pass

    # Google TTS
    try:
        tts = gTTS(text=clean_text, lang='vi')
        tts.save(filename)
        return True
    except: return False

def get_image_url(prompt, width=1280, height=720):
    # Giá»¯ nguyÃªn delay vÃ  random seed Ä‘á»ƒ trÃ¡nh rate limit
    time.sleep(random.uniform(1.0, 3.0)) 
    seed = random.randint(1, 10000000)
    ratio_prompt = ", vertical, tall, 9:16" if width < height else ", wide angle, cinematic, 16:9"
    style = ", high quality illustration, isometric style, flat design, cinematic lighting, no text"
    clean_prompt = (prompt + style + ratio_prompt).replace(" ", "%20")
    return f"https://image.pollinations.ai/prompt/{clean_prompt}?width={width}&height={height}&nologo=true&seed={seed}"

def process_scene(args):
    part, width, height, tone = args
    try:
        if "|" in part:
            data = part.split("|")
            if len(data) < 2: return None
            
            img_prompt = data[0].replace("Scene", "").replace(":", "").strip()
            raw_voice_text = data[1].strip()
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                audio_path = f.name
            
            success = generate_audio_unified(raw_voice_text, audio_path, tone)
            if not success: return None

            img_url = get_image_url(img_prompt, width, height)
            response = requests.get(img_url, timeout=20)
            if response.status_code == 200:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as f:
                    f.write(response.content); img_path = f.name
                return (audio_path, img_path)
            else: return None
    except: return None

def create_video_from_script(script_data, width, height, tone):
    lines = [line for line in script_data.strip().split('\n') if "|" in line and "Scene" in line]
    if len(lines) > 10: lines = lines[:10]
    total_scenes = len(lines)
    if total_scenes == 0: return None

    progress_bar = st.progress(0)
    status_text = st.empty()
    status_text.text(f"ğŸš€ Äang táº£i tÃ i nguyÃªn (Tone: {tone})...")
    
    process_args = [(line, width, height, tone) for line in lines]
    
    # Äa luá»“ng (Max 2 workers Ä‘á»ƒ an toÃ n áº£nh)
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        results = list(executor.map(process_scene, process_args))
        
    status_text.text("ğŸ¬ Äang render video...")
    clips = []
    for i, asset in enumerate(results):
        if asset:
            audio_path, img_path = asset
            try:
                ac = AudioFileClip(audio_path)
                clip = ImageClip(img_path).set_duration(ac.duration + 0.5).set_audio(ac).set_fps(15)
                clips.append(clip)
            except: pass
        progress_bar.progress(int((i + 1) / total_scenes * 100))

    if clips:
        try:
            final = concatenate_videoclips(clips, method="compose")
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as f:
                final.write_videofile(f.name, codec='libx264', audio_codec='aac', fps=15, preset='ultrafast', threads=4)
            status_text.text("âœ… Xong!")
            progress_bar.empty()
            return f.name
        except: return None
    return None

def render_mixed_content(text, width=800, height=450):
    pattern = r'\{{1,2}IMAGE:?\s*(.*?)\}{1,2}'
    parts = re.split(pattern, text, flags=re.IGNORECASE)
    for i, part in enumerate(parts):
        if i % 2 == 0:
            if part.strip(): st.markdown(part)
        else:
            img_prompt = part.strip().replace("}", "").replace("{", "")
            if img_prompt:
                img_url = get_image_url(img_prompt, width, height)
                st.image(img_url, caption=f"ğŸ¨ {img_prompt}", use_container_width=True)

# --- GIAO DIá»†N CHÃNH ---
st.title("ğŸ›¡ï¸ DAT Media AI Studio")

col1, col2 = st.columns([1, 1.5], gap="large")

with col1:
    st.subheader("1. Thiáº¿t láº­p ná»™i dung")
    keyword = st.text_input("Chá»§ Ä‘á» chÃ­nh", "Báº£o hiá»ƒm nhÃ¢n thá» cho ngÆ°á»i trá»¥ cá»™t")
    sector = st.selectbox("LÄ©nh vá»±c", ["Báº£o hiá»ƒm NhÃ¢n thá»", "Báº£o hiá»ƒm Phi NhÃ¢n thá»", "Báº£o hiá»ƒm Sá»©c khoáº»"])
    content_type = st.radio("Loáº¡i ná»™i dung", ["Clip (Video)", "BÃ i Website", "BÃ i Facebook"])
    
    seo_guide = ""
    video_w, video_h = 1280, 720
    
    if content_type == "Clip (Video)":
        orientation = st.radio("Khung hÃ¬nh:", ["Ngang 16:9 (YouTube)", "Dá»c 9:16 (TikTok/Shorts)"], horizontal=True)
        if "Ngang" in orientation:
            video_w, video_h = 1280, 720; ratio_txt = "Wide 16:9"
        else:
            video_w, video_h = 720, 1280; ratio_txt = "Vertical 9:16"

        vid_len = st.radio("Äá»™ dÃ i:", ["Clip Ngáº¯n (<90s)", "Video DÃ i (Preview)"], horizontal=True)
        if "Ngáº¯n" in vid_len: dur = st.slider("GiÃ¢y", 15, 90, 60); dur_txt = f"{dur} giÃ¢y"
        else: dur = st.slider("PhÃºt", 2, 20, 5); dur_txt = f"{dur} phÃºt"

        seo_guide = f"""
        - Viáº¿t Ká»‹ch báº£n Video ({ratio_txt}) dÃ i {dur_txt}.
        - Äá»‹nh dáº¡ng Báº®T BUá»˜C tá»«ng dÃ²ng: 'Scene X: [MÃ´ táº£ áº£nh tiáº¿ng Anh] | [Lá»i bÃ¬nh tiáº¿ng Viá»‡t]'.
        """
    elif content_type == "BÃ i Website":
        words = st.number_input("Sá»‘ tá»«", 500, 2500, 1000)
        seo_guide = f"- Viáº¿t bÃ i chuáº©n SEO {words} tá»«. Báº®T BUá»˜C dÃ¹ng tháº» {{IMAGE: english prompt}} xen káº½."
    else:
        seo_guide = "- Viáº¿t Caption Facebook thu hÃºt. Äá» xuáº¥t áº£nh vuÃ´ng."

    tone_options = ["ChuyÃªn nghiá»‡p", "Äá»i thÆ°á»ng", "Cáº£m Ä‘á»™ng", "HÃ i hÆ°á»›c"]
    tone = st.select_slider("Tone giá»ng & Phong cÃ¡ch", tone_options)
    
    btn_run = st.button("ğŸš€ Xá»¬ LÃ NGAY")

# --- Káº¾T QUáº¢ ---
with col2:
    st.subheader("2. Káº¿t quáº£")
    if btn_run:
        if not api_key: st.error("ChÆ°a káº¿t ná»‘i Gemini API")
        else:
            with st.spinner(f"AI Ä‘ang quÃ©t model vÃ  xá»­ lÃ½..."):
                try:
                    # LÆ°u cÃ i Ä‘áº·t video
                    st.session_state.video_settings = {'w': video_w, 'h': video_h}
                    st.session_state.tone_key = tone
                    
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel(selected_model) # Sá»­ dá»¥ng Model tá»« danh sÃ¡ch quÃ©t
                    
                    past_fb = "\n".join([f"- {fb}" for fb in st.session_state.feedback_history])
                    prompt = f"""
                    Chá»§ Ä‘á»: {keyword}. LÄ©nh vá»±c: {sector}. Tone: {tone}.
                    YÃŠU Cáº¦U Äáº¦U RA:
                    1. TIÃŠU Äá»€ CHUáº¨N SEO
                    2. 5 HASHTAGS & 5 TAGS
                    3. Ná»˜I DUNG: {seo_guide}
                    LÆ¯U Ã: KhÃ´ng dÃ¹ng dáº¥u ** trong lá»i bÃ¬nh.
                    LÆ¯U Ã USER: {past_fb}
                    """
                    response = model.generate_content(prompt)
                    st.session_state.result = response.text
                    st.session_state.type = content_type
                    st.session_state.kw = keyword
                    st.success("ÄÃ£ cÃ³ ná»™i dung!")
                except Exception as e: st.error(f"Lá»—i: {e}. HÃ£y thá»­ chá»n Model khÃ¡c á»Ÿ Sidebar.")

    if 'result' in st.session_state:
        if st.session_state.type == "BÃ i Website":
            st.image(get_image_url(f"{st.session_state.kw} insurance header", 1200, 628), use_container_width=True)
            render_mixed_content(st.session_state.result)
        elif st.session_state.type == "BÃ i Facebook":
            st.image(get_image_url(f"{st.session_state.kw} flat lay", 1080, 1080), width=450)
            st.markdown(st.session_state.result)
        else:
            tab1, tab2 = st.tabs(["ğŸ¬ Video Demo", "ğŸ“ Ká»‹ch báº£n"])
            with tab1:
                vw = st.session_state.video_settings['w']
                vh = st.session_state.video_settings['h']
                tk = st.session_state.get('tone_key', "ChuyÃªn nghiá»‡p")
                
                # Hiá»ƒn thá»‹ thÃ´ng tin giá»ng Ä‘ang dÃ¹ng
                voice_name_map = {"mJLZ5p8I7Pk81BHpKwbx": "Nam Sadoma", "foH7s9fX31wFFH2yqrFa": "Huyá»n", "1l0C0QA9c9jN22EmWiB0": "Jade", "JxmKvRaNYFidf0N27Vng": "SÆ¡n Tráº§n"}
                current_id = VOICE_MAP.get(tk, "")
                v_label = voice_name_map.get(current_id, "Máº·c Ä‘á»‹nh")
                
                if "ElevenLabs" in tts_provider:
                    st.info(f"ğŸ™ï¸ Äang dÃ¹ng giá»ng: **{v_label}** (Tone: {tk})")
                
                if st.button("ğŸ¥ Dá»±ng Video"):
                    v_path = create_video_from_script(st.session_state.result, vw, vh, tk)
                    if v_path: st.video(v_path)
            with tab2:
                st.text_area("Script", st.session_state.result, height=500)
