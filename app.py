import streamlit as st
import time
import os
import re
import requests
import asyncio
import tempfile
import edge_tts
import imageio_ffmpeg
from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips, ColorClip, TextClip, CompositeVideoClip
import google.generativeai as genai

# --- 1. C·∫§U H√åNH APP ---
st.set_page_config(page_title="Insurance Script Pro", layout="wide", page_icon="üõ°Ô∏è")

# --- CSS ---
st.markdown("""
    <style>
    .stButton>button {background-color: #0068C9; color: white; font-weight: bold; border-radius: 8px; height: 3em; width: 100%;}
    img {border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); margin: 10px 0;}
    .caption {font-style: italic; color: #555; text-align: center; font-size: 0.9em;}
    </style>
""", unsafe_allow_html=True)

# --- KI·ªÇM TRA FFMPEG ---
ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()
if not os.path.exists(ffmpeg_path):
    st.error("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y FFmpeg. H√£y t·∫°o file `packages.txt` tr√™n GitHub v·ªõi n·ªôi dung `ffmpeg`.")

# --- QU·∫¢N L√ù SESSION ---
if 'history' not in st.session_state: st.session_state.history = []
if 'video_settings' not in st.session_state: st.session_state.video_settings = {'w': 1280, 'h': 720}

# --- C·∫§U H√åNH VOICE ID ---
VOICE_MAP = {
    "Chuy√™n nghi·ªáp": "mJLZ5p8I7Pk81BHpKwbx",  # Nam Sadoma
    "ƒê·ªùi th∆∞·ªùng": "foH7s9fX31wFFH2yqrFa",     # Huyen
    "C·∫£m ƒë·ªông": "1l0C0QA9c9jN22EmWiB0",       # Jade
    "H√†i h∆∞·ªõc": "JxmKvRaNYFidf0N27Vng"        # Son Tran
}

# --- SIDEBAR ---
with st.sidebar:
    st.header("üéõÔ∏è C·∫•u h√¨nh h·ªá th·ªëng")
    if st.button("üîÑ L√ÄM M·ªöI (RESET)"):
        st.session_state.clear()
        st.rerun()

    # 1. NH·∫¨P KEY
    api_key = st.secrets.get("GEMINI_API_KEY", "").strip()
    eleven_api = st.secrets.get("ELEVEN_API_KEY", "").strip()
    hf_token = st.secrets.get("HUGGINGFACE_TOKEN", "").strip()

    if not api_key: api_key = st.text_input("Gemini API Key", type="password")
    if not eleven_api: eleven_api = st.text_input("ElevenLabs API Key", type="password")
    if not hf_token: hf_token = st.text_input("HuggingFace Token", type="password")

    if api_key: st.success("‚úÖ Gemini: OK")
    if eleven_api: st.success("‚úÖ ElevenLabs: OK")
    if hf_token: st.success("‚úÖ HuggingFace: OK")

    st.divider()
    
    # 2. MODULE QU√âT MODEL
    st.subheader("üß† B·ªô n√£o x·ª≠ l√Ω")
    available_models = []
    if api_key:
        try:
            genai.configure(api_key=api_key)
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    available_models.append(m.name)
        except: pass
    
    if not available_models:
        available_models = ["models/gemini-1.5-flash", "models/gemini-pro"]
        
    selected_model = st.selectbox("Ch·ªçn Model:", available_models, index=0)

    st.divider()

    # 3. GI·ªåNG ƒê·ªåC
    st.subheader("üîä Gi·ªçng ƒë·ªçc Video")
    tts_provider = st.selectbox("Server:", ["ElevenLabs (VIP)", "Microsoft (Mi·ªÖn ph√≠)"])
    edge_voice = "vi-VN-HoaiMyNeural"
    if "Microsoft" in tts_provider:
        edge_voice = st.selectbox("Gi·ªçng MS:", ["vi-VN-HoaiMyNeural (N·ªØ)", "vi-VN-NamMinhNeural (Nam)"]).split(" ")[0]

# --- H√ÄM X·ª¨ L√ù ---

def clean_text(text):
    text = re.sub(r'\[.*?\]|\(.*?\)', '', text)
    for p in ["L·ªùi b√¨nh:", "Audio:", "Voice:", "Scene \d+:", "MC:", "Host:"]:
        text = re.sub(f'{p}', '', text, flags=re.IGNORECASE)
    return text.replace("*", "").replace("#", "").replace("- ", "").replace('"', '').strip()

async def gen_edge_tts(text, voice, fname):
    await edge_tts.Communicate(text, voice).save(fname)

def gen_audio(text, fname, tone):
    text = clean_text(text)
    if not text: return False
    
    if "ElevenLabs" in tts_provider:
        if not eleven_api:
            st.warning("‚ö†Ô∏è Thi·∫øu ElevenLabs Key. D√πng Microsoft thay th·∫ø.")
        else:
            vid = VOICE_MAP.get(tone, "mJLZ5p8I7Pk81BHpKwbx")
            try:
                url = f"https://api.elevenlabs.io/v1/text-to-speech/{vid}"
                headers = {"xi-api-key": eleven_api, "Content-Type": "application/json"}
                data = {"text": text, "model_id": "eleven_turbo_v2_5"}
                res = requests.post(url, json=data, headers=headers, timeout=60)
                if res.status_code == 200:
                    with open(fname, 'wb') as f: f.write(res.content)
                    return True
            except: pass

    try:
        asyncio.run(gen_edge_tts(text, edge_voice, fname))
        return True
    except: return False

def gen_image_safe(prompt, w, h):
    """Chi·∫øn thu·∫≠t Hybrid: HF -> Pollinations -> Stock -> Placeholder"""
    # 1. Hugging Face
    if hf_token:
        API_URL = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"
        headers = {"Authorization": f"Bearer {hf_token}"}
        full_prompt = prompt + ", masterpiece, high quality, corporate insurance style, no text"
        full_prompt += ", vertical 9:16 portrait" if w < h else ", wide 16:9 landscape"
        try:
            res = requests.post(API_URL, headers=headers, json={"inputs": full_prompt}, timeout=15)
            if res.status_code == 200: 
                time.sleep(2) # Delay nh·∫π
                return res.content
        except: pass

    # 2. Pollinations (Th√™m delay v√† User-Agent ƒë·ªÉ tr√°nh Rate Limit)
    try:
        clean_prompt = prompt.replace(" ", "%20")
        url = f"https://image.pollinations.ai/prompt/{clean_prompt}?width={w}&height={h}&nologo=true&seed={int(time.time())}&model=flux"
        headers = {'User-Agent': 'Mozilla/5.0'}
        # Th·ª≠ t·ªëi ƒëa 2 l·∫ßn
        for _ in range(2):
            res = requests.get(url, headers=headers, timeout=20)
            if res.status_code == 200: return res.content
            time.sleep(2)
    except: pass

    # 3. Stock Backup (Picsum - Kh√¥ng bao gi·ªù l·ªói)
    try:
        stock_url = f"https://picsum.photos/seed/{int(time.time())}/{w}/{h}"
        res = requests.get(stock_url, timeout=10)
        if res.status_code == 200: return res.content
    except: pass

    return None

# --- H√ÄM X·ª¨ L√ù B√ÄI VI·∫æT WEBSITE (CAPTION TI·∫æNG VI·ªÜT) ---
def render_mixed_content(text):
    """
    X·ª≠ l√Ω th·∫ª {IMAGE: English Prompt | Caption Ti·∫øng Vi·ªát}
    """
    # Regex t√¨m th·∫ª {IMAGE: ...}
    parts = re.split(r'\{IMAGE:\s*(.*?)\}', text, flags=re.IGNORECASE)
    
    for i, part in enumerate(parts):
        if i % 2 == 0:
            if part.strip():
                st.markdown(part)
        else:
            # X·ª≠ l√Ω ph·∫ßn trong ngo·∫∑c
            raw_content = part.strip()
            
            # T√°ch Prompt (Anh) v√† Caption (Vi·ªát)
            if "|" in raw_content:
                prompt_en, caption_vn = raw_content.split("|", 1)
            else:
                prompt_en = raw_content
                caption_vn = "H√¨nh ·∫£nh minh h·ªça" # Fallback n·∫øu AI qu√™n t·∫°o caption

            prompt_en = prompt_en.strip()
            caption_vn = caption_vn.strip()

            if prompt_en:
                with st.spinner(f"üé® ƒêang v·∫Ω: {caption_vn}..."):
                    # G·ªçi h√†m Safe (C√≥ delay + fallback)
                    img_data = gen_image_safe(prompt_en, 800, 450)
                    if img_data:
                        st.image(img_data, use_container_width=True)
                        st.markdown(f"<div class='caption'>{caption_vn}</div>", unsafe_allow_html=True)
                        time.sleep(2) # Ngh·ªâ 2s sau m·ªói ·∫£nh ƒë·ªÉ tr√°nh Rate Limit
                    else:
                        st.warning(f"‚ö†Ô∏è Kh√¥ng t·∫£i ƒë∆∞·ª£c ·∫£nh: {caption_vn}")

def create_video(script, w, h, tone):
    lines = [l for l in script.split('\n') if "|" in l and ("Scene" in l or "C·∫£nh" in l)][:10]
    if not lines:
        st.error("‚ö†Ô∏è L·ªói k·ªãch b·∫£n: Kh√¥ng t√¨m th·∫•y d√≤ng 'Scene X: ... | ...'")
        return None
        
    st.info(f"üé¨ ƒêang x·ª≠ l√Ω {len(lines)} c·∫£nh...")
    bar = st.progress(0)
    
    clips = []
    
    for i, line in enumerate(lines):
        parts = line.split("|")
        if len(parts) < 2: continue
        
        img_p = parts[0].replace("Scene", "").replace(":", "").strip()
        aud_t = parts[1].strip()
        
        # 1. Audio
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f: af = f.name
        if not gen_audio(aud_t, af, tone): continue
        
        # 2. Image
        img_data = gen_image_safe(img_p, w, h)
        if img_data:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as f:
                f.write(img_data); img_path = f.name
        else:
            img_path = "PLACEHOLDER"
        
        # 3. Clip
        try:
            ac = AudioFileClip(af)
            dur = ac.duration + 0.5
            
            if img_path == "PLACEHOLDER":
                txt_clip = TextClip("ƒêang t·∫£i ·∫£nh...", fontsize=30, color='white', size=(w,h)).set_duration(dur)
                bg_clip = ColorClip(size=(w, h), color=(0,50,100), duration=dur)
                clip = CompositeVideoClip([bg_clip, txt_clip])
            else:
                clip = ImageClip(img_path).set_duration(dur)
            
            clip = clip.set_audio(ac).set_fps(15)
            clips.append(clip)
        except: pass
        
        bar.progress((i+1)/len(lines))
        
    if clips:
        try:
            final = concatenate_videoclips(clips, method="compose")
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as f:
                final.write_videofile(f.name, codec='libx264', audio_codec='aac', fps=15, preset='ultrafast', threads=4)
            bar.empty()
            return f.name
        except Exception as e:
            st.error(f"‚ùå L·ªói Render: {e}")
            return None
    return None

# --- UI CH√çNH ---
st.title("üõ°Ô∏è Insurance Script Pro")

col1, col2 = st.columns([1, 1.3], gap="large")

with col1:
    st.subheader("1. Thi·∫øt k·∫ø N·ªôi dung")
    
    c1, c2 = st.columns(2)
    with c1:
        pillar = st.selectbox("Pillar (Tr·ª• c·ªôt)", ["Ki·∫øn th·ª©c & Gi√°o d·ª•c", "S·∫£n ph·∫©m & Gi·∫£i ph√°p", "Ni·ªÅm tin & B·∫±ng ch·ª©ng", "Phong c√°ch s·ªëng"])
    with c2:
        angle = st.selectbox("Angle (G√≥c ƒë·ªô)", ["Chuy√™n gia ph√¢n t√≠ch", "K·ªÉ chuy·ªán (Storytelling)", "C·∫£nh b√°o (Drama)", "H√†i h∆∞·ªõc (Fun)", "Q&A Gi·∫£i ƒë√°p"])

    kw = st.text_input("Ch·ªß ƒë·ªÅ / T·ª´ kh√≥a", "B·∫£o hi·ªÉm nh√¢n th·ªç tr·ªçn ƒë·ªùi")
    
    st.write("---")
    fmt = st.radio("ƒê·ªãnh d·∫°ng:", ["Clip (Video)", "B√†i Website", "B√†i Facebook"], horizontal=True)
    
    vw, vh = 1280, 720
    seo_guide = ""
    
    if fmt == "Clip (Video)":
        ratio = st.radio("Khung h√¨nh:", ["Ngang 16:9", "D·ªçc 9:16"])
        vw, vh = (1280, 720) if "Ngang" in ratio else (720, 1280)
        dur = st.slider("Th·ªùi l∆∞·ª£ng (s)", 15, 90, 45)
        seo_guide = f"Vi·∫øt k·ªãch b·∫£n Video {dur}s. B·∫ÆT BU·ªòC m·ªói d√≤ng: 'Scene X: [M√¥ t·∫£ ·∫£nh ti·∫øng Anh] | [L·ªùi b√¨nh ti·∫øng Vi·ªát]'"
        
    elif fmt == "B√†i Website":
        words = st.slider("S·ªë t·ª´", 500, 2000, 1000)
        # S·ª¨A PROMPT ƒê·ªÇ T·∫†O CAPTION TI·∫æNG VI·ªÜT
        seo_guide = f"""
        Vi·∫øt b√†i chu·∫©n SEO {words} t·ª´. 
        QUY T·∫ÆC CH√àN ·∫¢NH (B·∫ÆT BU·ªòC):
        M·ªói ƒëo·∫°n vƒÉn h√£y ch√®n m·ªôt th·∫ª ·∫£nh theo ƒë·ªãnh d·∫°ng sau:
        {{IMAGE: [M√¥ t·∫£ ·∫£nh chi ti·∫øt b·∫±ng ti·∫øng Anh ƒë·ªÉ v·∫Ω] | [Caption ng·∫Øn g·ªçn ti·∫øng Vi·ªát d∆∞·ªõi 7 t·ª´]}}
        V√≠ d·ª•: {{IMAGE: A happy family holding hands in a park | Gia ƒë√¨nh h·∫°nh ph√∫c b√™n nhau}}
        """
        
    else:
        seo_guide = "Vi·∫øt Caption Facebook thu h√∫t. ƒê·ªÅ xu·∫•t ·∫£nh vu√¥ng."

    tone_map = {"Chuy√™n gia ph√¢n t√≠ch": "Chuy√™n nghi·ªáp", "K·ªÉ chuy·ªán (Storytelling)": "C·∫£m ƒë·ªông", "C·∫£nh b√°o (Drama)": "Chuy√™n nghi·ªáp", "H√†i h∆∞·ªõc (Fun)": "H√†i h∆∞·ªõc", "Q&A Gi·∫£i ƒë√°p": "ƒê·ªùi th∆∞·ªùng"}
    auto_tone = tone_map.get(angle, "Chuy√™n nghi·ªáp")
    st.info(f"üéôÔ∏è Tone t·ª± ƒë·ªông: **{auto_tone}**")

    if st.button("üöÄ X·ª¨ L√ù NGAY"):
        if not api_key: st.error("‚ùå Thi·∫øu Gemini Key")
        else:
            with st.spinner("AI ƒëang vi·∫øt..."):
                try:
                    model = genai.GenerativeModel(selected_model)
                    
                    prompt = f"""
                    Vai tr√≤: Chuy√™n gia Content B·∫£o Hi·ªÉm.
                    Topic: {kw}. Pillar: {pillar}. Angle: {angle}.
                    Y√äU C·∫¶U:
                    1. Ti√™u ƒë·ªÅ
                    2. Hashtags
                    3. N·ªôi dung: {seo_guide}
                    L∆∞u √Ω: Kh√¥ng d√πng d·∫•u ** trong l·ªùi b√¨nh video.
                    """
                    response = model.generate_content(prompt)
                    st.session_state.res = response.text
                    st.session_state.fmt = fmt
                    st.session_state.sets = {'w': vw, 'h': vh, 'tone': auto_tone}
                    st.session_state.kw = kw 
                    st.success("ƒê√£ xong!")
                except Exception as e:
                    st.error(f"‚ùå L·ªói AI: {e}")

with col2:
    st.subheader("2. K·∫øt qu·∫£")
    if 'res' in st.session_state:
        res = st.session_state.res
        ft = st.session_state.fmt
        sets = st.session_state.sets
        kw_saved = st.session_state.get('kw', 'insurance')
        
        if ft == "B√†i Website":
            # ·∫¢nh Featured
            st.info("üñºÔ∏è ·∫¢nh Featured")
            feat_img = gen_image_safe(f"{kw_saved} insurance header illustration", 1200, 628)
            if feat_img: 
                st.image(feat_img, use_container_width=True)
                st.markdown("<div class='caption'>·∫¢nh ƒë·∫°i di·ªán b√†i vi·∫øt</div>", unsafe_allow_html=True)
            
            st.write("---")
            render_mixed_content(res)
            
        elif ft == "B√†i Facebook":
            st.info("üì± ·∫¢nh Vu√¥ng")
            img = gen_image_safe(f"{kw_saved} flat lay", 1080, 1080)
            if img: st.image(img, width=450)
            st.markdown(res)
            
        else: # Video
            tab1, tab2 = st.tabs(["üé• Video", "üìù K·ªãch b·∫£n"])
            with tab1:
                st.caption(f"Server: {tts_provider} | Tone: {sets['tone']}")
                if st.button("üé¨ B·∫§M ƒê·ªÇ D·ª∞NG VIDEO"):
                    video_file = create_video(res, sets['w'], sets['h'], sets['tone'])
                    if video_file:
                        st.video(video_file)
            with tab2:
                st.text_area("Script", res, height=600)
